# test# Tema 3 ASC

**Autor:** Artiom Pujleacov  
**Grupa:** 334CB

---

## Interpretare analizÄƒ Cachegrind

### LegendÄƒ

- **I refs:** numÄƒrul de referinÈ›e la instrucÈ›iuni
- **I1/D1 misses:** ratÄƒri Ã®n cache-ul de nivel 1
- **D refs:** numÄƒr total de referinÈ›e la date (read/write)
- **LL misses:** ratÄƒri Ã®n cache-ul last level
- **Branches/Mispredicts:** salturi condiÈ›ionale/indirecte È™i cÃ¢t de des predicÈ›ia a fost greÈ™itÄƒ

| Metrica         | `neopt` | `opt_m` | `blas`      |
|-----------------|---------|---------|-------------|
| I refs          | 229.794 | 229.794 | 4.248.922   |
| D refs          | 65.916  | 65.916  | 1.668.226   |
| D1 miss rate    | 4.9%    | 4.9%    | 2.5%        |
| LL miss rate    | 1.3%    | 1.3%    | 0.3%        |
| Branches        | 45.110  | 45.110  | 611.437     |
| Mispredict rate | 12.2%   | 12.2%   | 4.6%        |

### Interpretare

- **BLAS** are un numÄƒr foarte mare de instrucÈ›iuni È™i referinÈ›e, dar o ratÄƒ micÄƒ de ratÄƒri Ã®n cache-ul de nivel 1 È™i last level, ceea ce indicÄƒ o bunÄƒ utilizare a cache-ului. De asemenea, are un numÄƒr mare de salturi condiÈ›ionale, dar cu o ratÄƒ micÄƒ de predicÈ›ie greÈ™itÄƒ, ceea ce sugereazÄƒ cÄƒ predicÈ›ia salturilor este eficientÄƒ. BLAS are ramificÄƒri predictibile sau puÈ›ine.
- Ãn schimb, `neopt` È™i `opt_m` au un numÄƒr mult mai mic de instrucÈ›iuni È™i referinÈ›e, dar o ratÄƒ de ratÄƒri Ã®n cache-ul de nivel 1 È™i last level mai mare, ceea ce indicÄƒ o utilizare mai puÈ›in eficientÄƒ a cache-ului. De asemenea, au un numÄƒr mai mic de salturi condiÈ›ionale, dar o ratÄƒ mai mare de predicÈ›ie greÈ™itÄƒ, ceea ce sugereazÄƒ o predicÈ›ie mai puÈ›in eficientÄƒ a salturilor. Rata mare de branch mispredict indicÄƒ cod cu multe if-uri imprevizibile.

**Concluzie:**  
`blas` este cea mai eficientÄƒ implementare Ã®n ceea ce priveÈ™te utilizarea cache-ului È™i predicÈ›ia salturilor, Ã®n timp ce `neopt` È™i `opt_m` au o utilizare mai puÈ›in eficientÄƒ a acestora.

---

## Efectul optimizÄƒrilor

DeÈ™i variantele `neopt` È™i `opt_m` au indicatori Cachegrind aproape identici (acelaÈ™i numÄƒr de referinÈ›e la instrucÈ›iuni È™i date, aceleaÈ™i rate de ratÄƒri Ã®n cache), `opt_m` este semnificativ mai rapid Ã®n execuÈ›ia realÄƒ. Acest lucru se datoreazÄƒ optimizÄƒrilor fÄƒcute manual Ã®n cod, care nu reduc neapÄƒrat numÄƒrul de accesÄƒri la memorie, dar:

- reduc numÄƒrul de operaÈ›ii inutile (de exemplu prin eliminarea recalculÄƒrilor sau buclelor ineficiente)
- rearanjeazÄƒ accesÄƒrile la memorie pentru a Ã®mbunÄƒtÄƒÈ›i localitatea spaÈ›ialÄƒ È™i temporalÄƒ
- folosesc structuri de date mai eficiente (ex: bucle "interchange", blocuri, evitarea cache miss-urilor prin acces secvenÈ›ial etc.)

Cachegrind mÄƒsoarÄƒ doar numÄƒrul de accesÄƒri, dar nu surprinde complet beneficiile precum:

- rulare mai rapidÄƒ pe CPU real datoritÄƒ unui cod mai compact È™i mai bine vectorizat
- reducerea latenÈ›elor cauzate de accesÄƒri haotice
- eliminarea unor operaÈ›ii complet prin optimizÄƒri (dead code, strength reduction, etc.)

DeÈ™i datele de cache sunt similare, `opt_m` are un timp de execuÈ›ie mai mic din cauza eficientizÄƒrii reale a codului È™i a utilizÄƒrii mai bune a procesorului.

---

## Analiza graficelor

### Timpii de execuÈ›ie

#### `opt_m`

```
N=200:  Time=0.042094
N=400:  Time=0.322833
N=600:  Time=1.076220
N=800:  Time=2.536097
N=1000: Time=4.948999
```

#### `neopt`

```
N=200:  Time=0.241318
N=400:  Time=2.037641
N=600:  Time=7.376293
N=800:  Time=16.650749
N=1000: Time=28.030949
```

#### `blas`

```
N=200:  Time=0.008862
N=400:  Time=0.066758
N=600:  Time=0.190512
N=800:  Time=0.425241
N=1000: Time=0.839287
```

Am adÄƒugat poza Ã®n arhivÄƒ sub numele `timpi.png`.

![Screenshot 2025-05-18 182627](https://github.com/user-attachments/assets/4ddb72a7-99b0-4143-afa6-1c6476c17da5)


### ObservaÈ›ii

- Implementarea `neopt` are cel mai mare timp de execuÈ›ie pentru valorile lui N. Timpul creÈ™te exponenÈ›ial cu dimensiunea, indicÃ¢nd un cod neoptimizat, cu acces ineficient la memorie È™i/sau fÄƒrÄƒ vectorizare.
- Implementarea `opt_m` are un timp de execuÈ›ie mai mic decÃ¢t `neopt`, dar mai mare decÃ¢t `blas`. Timpul de execuÈ›ie creÈ™te exponenÈ›ial cu dimensiunea, dar nu la fel de rapid ca Ã®n cazul `neopt`, ceea ce sugereazÄƒ cÄƒ optimizÄƒrile au avut un impact semnificativ asupra performanÈ›ei, dar nu la fel de mult ca optimizÄƒrile BLAS.
- Implementarea `blas` are cel mai mic timp de execuÈ›ie pentru toate dimensiunile, ceea ce sugereazÄƒ cÄƒ este cea mai eficientÄƒ implementare dintre cele trei. Timpul de execuÈ›ie creÈ™te mai lent decÃ¢t Ã®n cazul `neopt` È™i `opt_m`, ceea ce sugereazÄƒ cÄƒ BLAS utilizeazÄƒ o abordare mai eficientÄƒ pentru a gestiona dimensiunile mai mari ale datelor. De asemenea, BLAS are un timp de execuÈ›ie constant pentru dimensiuni mai mari, ceea ce sugereazÄƒ cÄƒ este capabil sÄƒ gestioneze eficient dimensiuni mari ale datelor fÄƒrÄƒ a afecta semnificativ performanÈ›a.

**Clasament eficienÈ›Äƒ:**  

1. BLAS  
2. opt_m  
3. neopt

---

## ExplicaÈ›ii implementÄƒri

### `neopt`

AceastÄƒ versiune realizeazÄƒ calculele cerute folosind bucle clasice `for`, fÄƒrÄƒ nicio formÄƒ de optimizare sau utilizare de biblioteci externe. Toate operaÈ›iile se fac Ã®n ordine:

1. Se calculeazÄƒ transpusa matricei A manual
2. Se face Ã®nmulÈ›irea matricei A transpuse cu vectorul x
3. Se Ã®nmulÈ›eÈ™te rezultatul cu matricea B
4. La final se adaugÄƒ vectorul y

Acest cod e simplu È™i uÈ™or de Ã®nÈ›eles, dar nu este optimizat pentru performanÈ›Äƒ.

### `opt_m`

AceastÄƒ versiune realizeazÄƒ aceleaÈ™i calcule, dar foloseÈ™te optimizÄƒri manuale:

- Reordonarea buclelor pentru a profita de cache-ul procesorului
- Evitarea calculelor repetate
- Utilizarea de blocuri sau prelucrÄƒri intermediare pentru a reduce dimensiunea datelor procesate la un moment dat

AceastÄƒ versiune oferÄƒ o performanÈ›Äƒ bunÄƒ fÄƒrÄƒ a necesita biblioteci externe.

### `blas`

AceastÄƒ versiune utilizeazÄƒ biblioteca BLAS (Basic Linear Algebra Subprograms), folosind `cblas_dgemv` pentru a efectua Ã®nmulÈ›irea matricei cu vectorul È™i `cblas_dgemm` pentru Ã®nmulÈ›irea matricei cu matrice.

---

## Prompt-uri È™i explicaÈ›ii suplimentare

Am folosit ChatGPT 4 pentru a rafina implementÄƒrile È™i a obÈ›ine variantele optimizate È™i neoptimizate, precum È™i pentru a Ã®nÈ›elege mai bine avantajele folosirii BLAS È™i a optimizÄƒrilor manuale.

```
request:
C = B * At
D = Ct * A
i = 0
while (i < N) {
    y = Ct * x
    x = C * y
    i += 1
}
y = D * x

hi,i need to implement these operations only using blas operations,this is the signature of the function:
double* my_solver(int N, double *A, double *B, double *x) {
	return NULL;
}



raspuns:
To implement the following operations using only BLAS routines inside the my_solver function:

c
C = B * At        // At is A transposed
D = Ct * A        // Ct is C transposed
loop N times:
    y = Ct * x
    x = C * y
y = D * x
You can use BLAS Level 3 routine cblas_dgemm for matrix-matrix multiplication and BLAS Level 2 routine cblas_dgemv for matrix-vector multiplication.

âœ… Solution:
Here's how you can implement it:

c
#include <cblas.h>
#include <stdlib.h>

double* my_solver(int N, double *A, double *B, double *x) {
    // Allocate matrices and vectors
    double *C = (double *)malloc(N * N * sizeof(double));
    double *Ct = (double *)malloc(N * N * sizeof(double));
    double *D = (double *)malloc(N * N * sizeof(double));
    double *y = (double *)malloc(N * sizeof(double));
    double *tmp = (double *)malloc(N * sizeof(double));

    // C = B * At  -> At is A transposed
    cblas_dgemm(CblasRowMajor, CblasNoTrans, CblasTrans,
                N, N, N, 1.0, B, N, A, N, 0.0, C, N);

    // Ct = C^T  (we transpose C manually)
    for (int i = 0; i < N; ++i)
        for (int j = 0; j < N; ++j)
            Ct[j * N + i] = C[i * N + j];

    // D = Ct * A
    cblas_dgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans,
                N, N, N, 1.0, Ct, N, A, N, 0.0, D, N);

    // Copy x to tmp (x will be updated)
    for (int i = 0; i < N; ++i)
        tmp[i] = x[i];

    // Repeat N times:
    //   y = Ct * x
    //   x = C * y
    for (int iter = 0; iter < N; ++iter) {
        cblas_dgemv(CblasRowMajor, CblasNoTrans,
                    N, N, 1.0, Ct, N, tmp, 1, 0.0, y, 1);

        cblas_dgemv(CblasRowMajor, CblasNoTrans,
                    N, N, 1.0, C, N, y, 1, 0.0, tmp, 1);
    }

    // Final y = D * x (x is now in tmp)
    cblas_dgemv(CblasRowMajor, CblasNoTrans,
                N, N, 1.0, D, N, tmp, 1, 0.0, y, 1);

    // Cleanup
    free(C);
    free(Ct);
    free(D);
    free(tmp);

    return y;
}
```

```
request:
how can i implement the manual transpose of the matrix using blas functions

raspuns:
BLAS does not provide a built-in function to transpose a matrix manually. The BLAS interface is designed for high-performance linear algebra operations, and transposition is typically handled implicitly via arguments in BLAS routines (e.g., using CblasTrans in cblas_dgemm).

âœ… Option 1: Use Transposition Flags in BLAS
Instead of manually transposing, you can tell BLAS to treat the matrix as transposed using the TransA or TransB flags.

Example:

c
cblas_dgemm(CblasRowMajor, CblasNoTrans, CblasTrans, ...);  // Use Aáµ— directly
So you don't need to transpose A or C manually for:

c
C = B * At
â†’ use:

c
cblas_dgemm(..., B, ..., A, ..., CblasTrans);
And for:

c
D = Ct * A
â†’ use:

c
cblas_dgemm(..., C, ..., A, ..., CblasTrans, CblasNoTrans); // Treat C as transposed
âœ… Option 2: Manual Transpose (only if required)
If you really need a separate transposed copy of a matrix, do it like this:

c
void transpose_matrix(int N, double *src, double *dst) {
    for (int i = 0; i < N; ++i)
        for (int j = 0; j < N; ++j)
            dst[j * N + i] = src[i * N + j]; // dst is the transpose of src
}
But again: this is outside of BLAS, and it's rarely necessary unless some other library requires the transposed matrix to be stored explicitly.
```

```
request:
now using the same signature,make a function just to manually do the operations i mentioned without using any external libraries

double* my_solver(int N, double *A, double *B, double *x) {
	return NULL;
}

raspuns:
Sure! Here's the complete function with a brief explanation and proper comments to help you understand what's happening at each step:

This implementation follows the operation sequence:

java
C = B * At       // At is the transpose of A
D = Ct * A       // Ct is the transpose of C
for i in 0 to N:
    y = Ct * x
    x = C * y
y = D * x        // Final result
Below is the full C function:

c
#include "utils.h"
#include <stdlib.h>
#include <string.h>

/*
 *
 *
 *
 *   C = B * At
 *   D = Ct * A
 *   for i = 0..N:
 *     y = Ct * x
 *     x = C * y
 *   y = D * x
 *
 */
double *my_solver(int N, double *A, double *B, double *x)
{
	double *At = (double *)malloc(N * N * sizeof(double));
	double *C = (double *)malloc(N * N * sizeof(double));
	double *Ct = (double *)malloc(N * N * sizeof(double));
	double *D = (double *)malloc(N * N * sizeof(double));
	double *y = (double *)malloc(N * sizeof(double));
	double *tmp = (double *)malloc(N * sizeof(double));
	double *result = (double *)malloc(N * sizeof(double));

	for (int i = 0; i < N; ++i)
		for (int j = 0; j < N; ++j)
			At[j * N + i] = A[i * N + j];

	// C = B * At
	for (int i = 0; i < N; ++i)
		for (int j = 0; j < N; ++j)
		{
			C[i * N + j] = 0.0;
			for (int k = 0; k < N; ++k)
				C[i * N + j] += B[i * N + k] * At[k * N + j];
		}

	// Ct = transpose C
	for (int i = 0; i < N; ++i)
		for (int j = 0; j < N; ++j)
			Ct[j * N + i] = C[i * N + j];

	// D = Ct * A
	for (int i = 0; i < N; ++i)
		for (int j = 0; j < N; ++j)
		{
			D[i * N + j] = 0.0;
			for (int k = 0; k < N; ++k)
				D[i * N + j] += Ct[i * N + k] * A[k * N + j];
		}

	memcpy(tmp, x, N * sizeof(double));

	//y = Ct * x; x = C * y;
	for (int iter = 0; iter < N; ++iter)
	{
		// y = Ct * tmp
		for (int i = 0; i < N; ++i)
		{
			y[i] = 0.0;
			for (int j = 0; j < N; ++j)
				y[i] += Ct[i * N + j] * tmp[j];
		}

		// tmp = C * y
		for (int i = 0; i < N; ++i)
		{
			tmp[i] = 0.0;
			for (int j = 0; j < N; ++j)
				tmp[i] += C[i * N + j] * y[j];
		}
	}

	// result = D * tmp
	for (int i = 0; i < N; ++i)
	{
		result[i] = 0.0;
		for (int j = 0; j < N; ++j)
			result[i] += D[i * N + j] * tmp[j];
	}

	free(At);
	free(C);
	free(Ct);
	free(D);
	free(y);
	free(tmp);

	return result;
}
âœ… This implementation is pure C, without using BLAS or any external libraries.

ğŸ’¡ If performance becomes important, this same structure can later be rewritten using cblas_dgemm and cblas_dgemv from BLAS for significant speedups.

Let me know if you want that BLAS version too!
```

```
request:
now suggest a way to optimize the give function to make it faster,without using external 
librarier,without chnaging the complexity of the operations

raspuns:
To optimize your function without using external libraries and without changing the algorithmic complexity, you can apply cache-friendly and low-level optimizations. These focus on improving data locality, reducing memory access cost, and avoiding redundant computations.

âœ… Suggested Optimizations:
1. Loop Order Optimization for Better Cache Locality
Matrix multiplications currently use:

c
for (i)
  for (j)
    for (k)
      result[i][j] += A[i][k] * B[k][j];
This accesses matrix B[k][j] column-wise (non-contiguous in memory), which is cache-inefficient. You can change the loop order to:

c
for (i)
  for (k)
    for (j)
      result[i][j] += A[i][k] * B[k][j];
This makes all three accesses mostly row-wise and improves CPU cache performance significantly.

2. Manual Blocking (Tiling)
Divide large matrices into small blocks to take better advantage of the CPU cache (L1/L2).

Example block size:

c
#define BLOCK_SIZE 32
Then modify the matrix multiplication to work in blocks:

c
for (ii = 0; ii < N; ii += BLOCK_SIZE)
  for (kk = 0; kk < N; kk += BLOCK_SIZE)
    for (jj = 0; jj < N; jj += BLOCK_SIZE)
      for (i = ii; i < min(ii + BLOCK_SIZE, N); ++i)
        for (k = kk; k < min(kk + BLOCK_SIZE, N); ++k)
          for (j = jj; j < min(jj + BLOCK_SIZE, N); ++j)
            C[i * N + j] += A[i * N + k] * B[k * N + j];
This improves spatial locality and cache reuse.

3. Avoid Recomputing Transposes
Instead of repeatedly computing the transpose, compute it once and reuse it. You already do this for At and Ct, which is great â€” just ensure you never re-transpose or access transposed matrices inefficiently afterward.

4. Use restrict Keyword (Optional)
If you are compiling with a modern compiler (e.g., GCC/Clang), you can tell the compiler that pointers donâ€™t alias:

c
double *restrict A, *restrict B, *restrict C;
This allows the compiler to optimize more aggressively.

5. Minimize memcpy
The line:

c
memcpy(tmp, x, N * sizeof(double));
is fine, but if x is not reused afterward, consider just working with tmp = x directly (carefully, only if you're sure x won't be reused or overwritten unexpectedly). This saves memory copy time.

6. Unroll Small Loops
For small fixed-size loops like:

c
for (int j = 0; j < N; ++j)
If N is small and fixed, manually unroll the loop or let the compiler do it using #pragma unroll.

Summary Table
Optimization	Gains	Cost / Risk
Loop order change (ijk â†’ ikj)	High (cache-friendly)	None
Manual tiling	Very High	More code
Avoid recomputing transposes	Moderate	Already done
Use restrict keyword	Moderate	Compiler-dependent
Minimize memcpy usage	Low	Code clarity
Manual loop unrolling	Low-Moderate	Code complexity
```

---

## Bucla N

Ultimele trei operaÈ›ii din enunÈ› implicÄƒ lucrul cu vectori È™i matrici de dimensiune N, iar rezultatul final al fiecÄƒreia dintre aceste operaÈ›ii este un vector coloanÄƒ de dimensiune N x 1. Pentru a obÈ›ine acest vector, este necesar sÄƒ se calculeze fiecare element al sÄƒu Ã®n parte, deoarece fiecare poziÈ›ie a rezultatului depinde de valorile corespunzÄƒtoare din liniile matricilor implicate È™i din vectorii utilizaÈ›i.

De aceea, se foloseÈ™te o buclÄƒ care se repetÄƒ de N ori, o datÄƒ pentru fiecare linie a matricii. Ãn cadrul fiecÄƒrei iteraÈ›ii se realizeazÄƒ calculele specifice pentru poziÈ›ia respectivÄƒ din vectorul rezultat. AceastÄƒ abordare permite construirea pas cu pas a vectorului final È™i este esenÈ›ialÄƒ pentru a asigura corectitudinea È™i completitudinea rezultatului.

**Ãn concluzie**, bucla de dimensiune N este esenÈ›ialÄƒ pentru a obÈ›ine vectorul rezultat corect È™i complet, deoarece permite parcurgerea tuturor liniilor matricilor È™i vectorilor implicaÈ›i Ã®n operaÈ›iile de Ã®nmulÈ›ire È™i adunare.
